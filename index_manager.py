# -*- coding: utf-8 -*-
"""index_manager.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M3my4DXkJ3-lenRCM0wsI6P2cEK49rBq

#### Elasticsearch Index Manager
"""

"""
Elasticsearch index manager for document indexing and searching.
"""

from typing import List, Dict, Optional
from datetime import datetime

from elasticsearch import Elasticsearch, NotFoundError, ConnectionError as ESConnectionError
from elasticsearch.helpers import bulk

from config import config
from src.utils import setup_logger

logger = setup_logger(__name__, config.LOG_FILE, config.LOG_LEVEL)


class IndexManager:
    """Manages Elasticsearch index operations."""

    def __init__(self):
        """Initialize Elasticsearch client."""
        self.index_name = config.ELASTICSEARCH_INDEX
        self.client = None
        self._connect()

    def _connect(self):
        """Connect to Elasticsearch."""
        try:
            # Basic auth if credentials provided
            if config.ELASTICSEARCH_USER and config.ELASTICSEARCH_PASSWORD:
                self.client = Elasticsearch(
                    [config.get_elasticsearch_url()],
                    basic_auth=(config.ELASTICSEARCH_USER, config.ELASTICSEARCH_PASSWORD),
                    verify_certs=False,
                    request_timeout=30
                )
            else:
                self.client = Elasticsearch(
                    [config.get_elasticsearch_url()],
                    verify_certs=False,
                    request_timeout=30
                )

            # Test connection
            if self.client.ping():
                logger.info(f"Connected to Elasticsearch at {config.get_elasticsearch_url()}")
            else:
                raise ESConnectionError("Failed to ping Elasticsearch")

        except Exception as e:
            logger.error(f"Failed to connect to Elasticsearch: {e}")
            raise

    def create_index(self, delete_existing: bool = False):
        """
        Create Elasticsearch index with mappings.

        Args:
            delete_existing: Delete existing index if it exists
        """
        try:
            # Delete existing index if requested
            if delete_existing and self.client.indices.exists(index=self.index_name):
                self.client.indices.delete(index=self.index_name)
                logger.info(f"Deleted existing index: {self.index_name}")

            # Check if index exists
            if self.client.indices.exists(index=self.index_name):
                logger.info(f"Index already exists: {self.index_name}")
                return

            # Define index mappings
            mappings = {
                "mappings": {
                    "properties": {
                        "file_id": {"type": "keyword"},
                        "file_name": {"type": "text", "fields": {"keyword": {"type": "keyword"}}},
                        "file_extension": {"type": "keyword"},
                        "content": {"type": "text", "analyzer": "standard"},
                        "mime_type": {"type": "keyword"},
                        "size": {"type": "long"},
                        "modified_time": {"type": "date"},
                        "web_view_link": {"type": "keyword"},
                        "web_content_link": {"type": "keyword"},
                        "indexed_at": {"type": "date"}
                    }
                },
                "settings": {
                    "number_of_shards": 1,
                    "number_of_replicas": 0,
                    "analysis": {
                        "analyzer": {
                            "default": {
                                "type": "standard"
                            }
                        }
                    }
                }
            }

            self.client.indices.create(index=self.index_name, body=mappings)
            logger.info(f"Created index: {self.index_name}")

        except Exception as e:
            logger.error(f"Failed to create index: {e}")
            raise

    def index_document(self, file_id: str, file_name: str, content: str,
                      metadata: Dict) -> bool:
        """
        Index a single document.

        Args:
            file_id: Unique file identifier
            file_name: Name of the file
            content: Extracted text content
            metadata: Additional file metadata

        Returns:
            True if successful, False otherwise
        """
        try:
            from pathlib import Path

            document = {
                "file_id": file_id,
                "file_name": file_name,
                "file_extension": Path(file_name).suffix.lower(),
                "content": content,
                "mime_type": metadata.get("mimeType", ""),
                "size": int(metadata.get("size", 0)),
                "modified_time": metadata.get("modifiedTime", ""),
                "web_view_link": metadata.get("webViewLink", ""),
                "web_content_link": metadata.get("webContentLink", ""),
                "indexed_at": datetime.utcnow().isoformat()
            }

            self.client.index(index=self.index_name, id=file_id, document=document)
            logger.debug(f"Indexed document: {file_name} (ID: {file_id})")
            return True

        except Exception as e:
            logger.error(f"Failed to index document {file_name}: {e}")
            return False

    def bulk_index_documents(self, documents: List[Dict]) -> tuple:
        """
        Bulk index multiple documents.

        Args:
            documents: List of document dictionaries

        Returns:
            Tuple of (success_count, failed_count)
        """
        try:
            actions = []
            for doc in documents:
                action = {
                    "_index": self.index_name,
                    "_id": doc["file_id"],
                    "_source": doc
                }
                actions.append(action)

            success, failed = bulk(self.client, actions, raise_on_error=False)
            logger.info(f"Bulk indexed: {success} successful, {len(failed)} failed")
            return success, len(failed)

        except Exception as e:
            logger.error(f"Bulk indexing failed: {e}")
            return 0, len(documents)

    def search(self, query: str, size: int = 100) -> List[Dict]:
        """
        Search for documents containing the query term.

        Args:
            query: Search query
            size: Maximum number of results

        Returns:
            List of matching documents
        """
        try:
            # Build search query
            search_body = {
                "query": {
                    "multi_match": {
                        "query": query,
                        "fields": ["content", "file_name"],
                        "type": "best_fields",
                        "operator": "or"
                    }
                },
                "size": size,
                "_source": ["file_id", "file_name", "web_view_link", "web_content_link",
                           "modified_time", "size"]
            }

            response = self.client.search(index=self.index_name, body=search_body)

            results = []
            for hit in response['hits']['hits']:
                result = hit['_source']
                result['score'] = hit['_score']
                results.append(result)

            logger.info(f"Search for '{query}' returned {len(results)} results")
            return results

        except NotFoundError:
            logger.warning(f"Index {self.index_name} not found")
            return []
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []

    def delete_document(self, file_id: str) -> bool:
        """
        Delete a document from the index.

        Args:
            file_id: File identifier

        Returns:
            True if successful, False otherwise
        """
        try:
            self.client.delete(index=self.index_name, id=file_id)
            logger.info(f"Deleted document: {file_id}")
            return True
        except NotFoundError:
            logger.warning(f"Document not found: {file_id}")
            return False
        except Exception as e:
            logger.error(f"Failed to delete document {file_id}: {e}")
            return False

    def document_exists(self, file_id: str) -> bool:
        """
        Check if a document exists in the index.

        Args:
            file_id: File identifier

        Returns:
            True if document exists, False otherwise
        """
        try:
            return self.client.exists(index=self.index_name, id=file_id)
        except Exception:
            return False

    def get_all_indexed_file_ids(self) -> List[str]:
        """
        Get all file IDs currently in the index.

        Returns:
            List of file IDs
        """
        try:
            search_body = {
                "query": {"match_all": {}},
                "size": 10000,
                "_source": ["file_id"]
            }

            response = self.client.search(index=self.index_name, body=search_body)
            file_ids = [hit['_source']['file_id'] for hit in response['hits']['hits']]

            logger.info(f"Found {len(file_ids)} indexed documents")
            return file_ids

        except NotFoundError:
            logger.warning(f"Index {self.index_name} not found")
            return []
        except Exception as e:
            logger.error(f"Failed to get indexed file IDs: {e}")
            return []

    def get_index_stats(self) -> Dict:
        """
        Get index statistics.

        Returns:
            Dictionary with index statistics
        """
        try:
            stats = self.client.indices.stats(index=self.index_name)
            count = self.client.count(index=self.index_name)

            return {
                "document_count": count['count'],
                "index_size_bytes": stats['indices'][self.index_name]['total']['store']['size_in_bytes'],
                "index_name": self.index_name
            }
        except Exception as e:
            logger.error(f"Failed to get index stats: {e}")
            return {}